{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc26c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from xgboost import XGBRegressor, DMatrix\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0ee19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342bfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"transform/train_transform_after_preparation.csv\")\n",
    "test = pd.read_csv(\"transform/test_transform_after_preparation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5375771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1456, 346)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2edbd2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 345)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39afd90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.207668</td>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.322669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255591</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.446984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.217252</td>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.10125</td>\n",
       "      <td>0.222121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.191693</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.688406</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.098720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.268371</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.299360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 346 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1    0.235294     0.207668  0.033420     0.666667        0.500   0.050725   \n",
       "1   2    0.000000     0.255591  0.038795     0.555556        0.875   0.246377   \n",
       "2   3    0.235294     0.217252  0.046507     0.666667        0.500   0.065217   \n",
       "3   4    0.294118     0.191693  0.038561     0.666667        0.500   0.688406   \n",
       "4   5    0.235294     0.268371  0.060576     0.777778        0.500   0.072464   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_New  SaleType_Oth  \\\n",
       "0      0.116667     0.12250    0.322669  ...           0.0           0.0   \n",
       "1      0.566667     0.00000    0.446984  ...           0.0           0.0   \n",
       "2      0.133333     0.10125    0.222121  ...           0.0           0.0   \n",
       "3      0.666667     0.00000    0.098720  ...           0.0           0.0   \n",
       "4      0.166667     0.21875    0.299360  ...           0.0           0.0   \n",
       "\n",
       "   SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0          1.0                    0.0                    0.0   \n",
       "1          1.0                    0.0                    0.0   \n",
       "2          1.0                    0.0                    0.0   \n",
       "3          1.0                    1.0                    0.0   \n",
       "4          1.0                    0.0                    0.0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                   0.0                   0.0                   1.0   \n",
       "1                   0.0                   0.0                   1.0   \n",
       "2                   0.0                   0.0                   1.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   1.0   \n",
       "\n",
       "   SaleCondition_Partial  SalePrice  \n",
       "0                    0.0     208500  \n",
       "1                    0.0     181500  \n",
       "2                    0.0     223500  \n",
       "3                    0.0     140000  \n",
       "4                    0.0     250000  \n",
       "\n",
       "[5 rows x 346 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189322d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.184147</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.374046</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.232124</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.396947</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.230175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.224197</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.154326</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.091603</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.064121</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
       "0  1461    0.000000        0.400  0.184147     0.444444        0.625   \n",
       "1  1462    0.000000        0.405  0.232124     0.555556        0.625   \n",
       "2  1463    0.235294        0.370  0.224197     0.444444        0.500   \n",
       "3  1464    0.235294        0.390  0.154326     0.555556        0.625   \n",
       "4  1465    0.588235        0.215  0.064121     0.777778        0.500   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
       "0   0.374046      0.816667    0.000000    0.116708  ...             0.0   \n",
       "1   0.396947      0.866667    0.083721    0.230175  ...             0.0   \n",
       "2   0.099237      0.200000    0.000000    0.197257  ...             0.0   \n",
       "3   0.091603      0.200000    0.015504    0.150125  ...             0.0   \n",
       "4   0.137405      0.300000    0.000000    0.065586  ...             0.0   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0           0.0           0.0          1.0                    0.0   \n",
       "1           0.0           0.0          1.0                    0.0   \n",
       "2           0.0           0.0          1.0                    0.0   \n",
       "3           0.0           0.0          1.0                    0.0   \n",
       "4           0.0           0.0          1.0                    0.0   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                    0.0                   0.0                   0.0   \n",
       "1                    0.0                   0.0                   0.0   \n",
       "2                    0.0                   0.0                   0.0   \n",
       "3                    0.0                   0.0                   0.0   \n",
       "4                    0.0                   0.0                   0.0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                   1.0                    0.0  \n",
       "1                   1.0                    0.0  \n",
       "2                   1.0                    0.0  \n",
       "3                   1.0                    0.0  \n",
       "4                   1.0                    0.0  \n",
       "\n",
       "[5 rows x 345 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e74967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7724/4110873382.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = train.drop(['SalePrice', 'Id'], 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['SalePrice', 'Id'], 1)\n",
    "y_train = np.log(train['SalePrice'])\n",
    "#y = train['SalePrice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c29f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7724/3814880248.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = test.drop('Id', 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop('Id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ca5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring = \"neg_mean_squared_error\", cv = 5).mean())\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "264f52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv_search(mse_mean):\n",
    "    rmse= np.sqrt(-mse_mean)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0e4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(search, name='NAN'):\n",
    "    \n",
    "    rcols = ['Name','Model', 'BestParameters', 'Scorer', 'Index', 'BestScore', 'BestScoreStd', 'Best Score Search']\n",
    "    res = pd.DataFrame(columns=rcols)\n",
    "    \n",
    "    results = search.cv_results_\n",
    "    model = search.best_estimator_\n",
    "\n",
    "    scoring = {'MEA': 'neg_mean_absolute_error', 'R2': 'r2', 'RMSE': 'neg_mean_squared_error'}\n",
    "\n",
    "    for scorer in sorted(scoring):\n",
    "        best_index = search.best_index_\n",
    "        if scorer == 'RMSE': \n",
    "            best = np.sqrt(-results['mean_test_%s' % scoring[scorer]][best_index])\n",
    "            best_std = np.sqrt(results['std_test_%s' % scoring[scorer]][best_index])\n",
    "        elif scorer == 'MEA':\n",
    "            best = (-results['mean_test_%s' % scoring[scorer]][best_index])\n",
    "            best_std = results['std_test_%s' % scoring[scorer]][best_index]\n",
    "        else:\n",
    "            best = results['mean_test_%s' % scoring[scorer]][best_index]*100\n",
    "            best_std = results['std_test_%s' % scoring[scorer]][best_index]*100\n",
    "        \n",
    "        r1 = pd.DataFrame([(name, model, search.best_params_, scorer, best_index, best, best_std, search.best_score_)],\n",
    "                          columns = rcols)\n",
    "        res = res.append(r1)\n",
    "        \n",
    "        bestscore = np.sqrt(-search.best_score_)\n",
    "        \n",
    "    print(\"Best Score: {:.6f}\".format(bestscore))\n",
    "    print('---------------------------------------')\n",
    "    print('Best Parameters:')\n",
    "    print(search.best_params_)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e0f8a",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "66309a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "37cbbf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "1d05ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Training set : 6095943657.116753\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on Training set :\", rmse_cv(linReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9d634",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "156427a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeEst = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "78d61d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0003, 0.0007, 0.0005, 0.05, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "max_iter = [5] # , 10, 100, 200, 300, 400, 500, 600, 1000]\n",
    "tol = [2e-03, 0.003, 0.001, 0.0005]\n",
    "\n",
    "param_ridge =\\\n",
    "            dict(\n",
    "                  alpha = alpha,\n",
    "                  max_iter = max_iter,\n",
    "                  tol = tol\n",
    "                ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ee4bf",
   "metadata": {},
   "source": [
    "### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "4685a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RandomizedSearchCV(estimator = ridgeEst, param_distributions = param_ridge, n_iter = 30,\n",
    "                           scoring=['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2'],\n",
    "                           n_jobs=-1, refit = 'neg_mean_squared_error',\n",
    "                           cv = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f54c262c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=Ridge(), n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0003, 0.0007, 0.0005, 0.05,\n",
       "                                                  0.5, 1.0, 2.0, 5.0, 10.0],\n",
       "                                        'max_iter': [5],\n",
       "                                        'tol': [0.002, 0.003, 0.001, 0.0005]},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
       "                            'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "963d49a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.0005, 'max_iter': 5, 'alpha': 5.0}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "97f9eb2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.116646\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'tol': 0.0005, 'max_iter': 5, 'alpha': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEA</td>\n",
       "      <td>11</td>\n",
       "      <td>0.081512</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>11</td>\n",
       "      <td>91.306854</td>\n",
       "      <td>0.727997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>11</td>\n",
       "      <td>0.116646</td>\n",
       "      <td>0.040267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd\n",
       "0    MEA    11   0.081512      0.003166\n",
       "0     R2    11  91.306854      0.727997\n",
       "0   RMSE    11   0.116646      0.040267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge_results = get_results(ridge, 'ridge')\n",
    "display(ridge_results.loc[:, 'Scorer' : 'BestScoreStd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4359f205",
   "metadata": {},
   "source": [
    "#  Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "158b8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoEst = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3d526067",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0003, 0.0007, 0.0005, 0.05, 0.5, 1.0]\n",
    "max_iter = [5 , 10, 100, 200, 300, 400, 500, 600, 1000]\n",
    "tol = [2e-03, 0.003, 0.001, 0.0005]\n",
    "selection = ['random', 'cyclic'] \n",
    "\n",
    "param_lasso =\\\n",
    "            dict(\n",
    "                alpha = alpha,\n",
    "                max_iter = max_iter,\n",
    "                tol = tol,\n",
    "                selection = selection\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "100d72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = RandomizedSearchCV(estimator = lassoEst, param_distributions = param_lasso, n_iter = 30,\n",
    "                           scoring=['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2'],\n",
    "                           n_jobs=-1, refit = 'neg_mean_squared_error',\n",
    "                           cv = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "96d5a40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-01, tolerance: 1.141e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=Lasso(), n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0003, 0.0007, 0.0005, 0.05,\n",
       "                                                  0.5, 1.0],\n",
       "                                        'max_iter': [5, 10, 100, 200, 300, 400,\n",
       "                                                     500, 600, 1000],\n",
       "                                        'selection': ['random', 'cyclic'],\n",
       "                                        'tol': [0.002, 0.003, 0.001, 0.0005]},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
       "                            'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e5aa9684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.0005, 'selection': 'random', 'max_iter': 300, 'alpha': 0.0003}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3c76e9ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.110943\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'tol': 0.0005, 'selection': 'random', 'max_iter': 300, 'alpha': 0.0003}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEA</td>\n",
       "      <td>23</td>\n",
       "      <td>0.077609</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>23</td>\n",
       "      <td>92.139543</td>\n",
       "      <td>0.785565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>23</td>\n",
       "      <td>0.110943</td>\n",
       "      <td>0.040799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd\n",
       "0    MEA    23   0.077609      0.002310\n",
       "0     R2    23  92.139543      0.785565\n",
       "0   RMSE    23   0.110943      0.040799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_results = get_results(lasso, 'lasso')\n",
    "display(lasso_results.loc[:, 'Scorer' : 'BestScoreStd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92254a12",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "afd63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnetEst = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "32f2d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0003, 0.0007, 0.0005, 0.05, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "l1_ratio = [0, 0.01, 0.1, 0.2, 0.5, 0.7, 0.9, 0.99, 1.0,]\n",
    "max_iter = [5, 10, 100, 200, 300, 400, 500, 600, 1000]\n",
    "tol = [2e-03, 0.003, 0.001, 0.0005]\n",
    "selection = ['random', 'cyclic'] \n",
    "\n",
    "param_elasticnet =\\\n",
    "            dict(\n",
    "                alpha = alpha,\n",
    "                l1_ratio = l1_ratio,\n",
    "                max_iter = max_iter,\n",
    "                tol = tol,\n",
    "                selection = selection\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "dc6b68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet = RandomizedSearchCV(estimator = elasticnetEst, param_distributions = param_elasticnet, n_iter = 75,\n",
    "                           scoring=['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2'],\n",
    "                           n_jobs=-1, refit = 'neg_mean_squared_error',\n",
    "                           cv = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f0438734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=ElasticNet(), n_iter=75, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0003, 0.0007, 0.0005, 0.05,\n",
       "                                                  0.5, 1.0, 2.0, 5.0, 10.0],\n",
       "                                        'l1_ratio': [0, 0.01, 0.1, 0.2, 0.5,\n",
       "                                                     0.7, 0.9, 0.99, 1.0],\n",
       "                                        'max_iter': [5, 10, 100, 200, 300, 400,\n",
       "                                                     500, 600, 1000],\n",
       "                                        'selection': ['random', 'cyclic'],\n",
       "                                        'tol': [0.002, 0.003, 0.001, 0.0005]},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
       "                            'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "f99b91b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.001,\n",
       " 'selection': 'cyclic',\n",
       " 'max_iter': 1000,\n",
       " 'l1_ratio': 1.0,\n",
       " 'alpha': 0.0003}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5b5f142c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.110979\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'tol': 0.001, 'selection': 'cyclic', 'max_iter': 1000, 'l1_ratio': 1.0, 'alpha': 0.0003}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEA</td>\n",
       "      <td>73</td>\n",
       "      <td>0.077606</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>73</td>\n",
       "      <td>92.134347</td>\n",
       "      <td>0.773922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>73</td>\n",
       "      <td>0.110979</td>\n",
       "      <td>0.040623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd\n",
       "0    MEA    73   0.077606      0.002243\n",
       "0     R2    73  92.134347      0.773922\n",
       "0   RMSE    73   0.110979      0.040623"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elasticnet_results = get_results(elasticnet, 'elasticnet')\n",
    "display(elasticnet_results.loc[:, 'Scorer' : 'BestScoreStd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e24172",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5dc3f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestRegEst = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "3a422dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5, 10, 20, 40, 80, 100, 150, 300, 600, 1000]\n",
    "criterion = ['squared_error', 'absolute_error', 'poisson']\n",
    "max_depth = [5, 10, 15, 20, 30, None]\n",
    "min_samples_split = [2, 3, 5, 7, 10]\n",
    "min_samples_leaf = [2, 3, 4]\n",
    "\n",
    "param_RFR =\\\n",
    "            dict(\n",
    "                n_estimators = n_estimators,\n",
    "                criterion = criterion,\n",
    "                max_depth = max_depth,\n",
    "                min_samples_split = min_samples_split,\n",
    "                min_samples_leaf = min_samples_leaf\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9b44f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestReg = RandomizedSearchCV(estimator = randomForestRegEst, param_distributions = param_RFR, n_iter = 15,\n",
    "                           scoring=['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2'],\n",
    "                           n_jobs=-1, refit = 'neg_mean_squared_error',\n",
    "                           cv = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a0b80bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e-01, tolerance: 9.280e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.890e+00, tolerance: 1.846e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.712e+00, tolerance: 5.444e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.198e+00, tolerance: 5.568e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.262e-01, tolerance: 3.629e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+01, tolerance: 3.510e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.759e+00, tolerance: 5.574e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e-01, tolerance: 9.228e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.236e-01, tolerance: 8.774e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e-01, tolerance: 9.074e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.771e+00, tolerance: 5.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 5.444e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.291e+00, tolerance: 5.568e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+00, tolerance: 5.574e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.350e-01, tolerance: 1.846e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+00, tolerance: 3.510e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.376e+00, tolerance: 1.856e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.921e+00, tolerance: 1.858e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.840e+00, tolerance: 3.629e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.311e+00, tolerance: 3.712e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.552e+01, tolerance: 5.574e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.888e+00, tolerance: 1.858e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+01, tolerance: 3.691e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+01, tolerance: 3.510e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+01, tolerance: 3.629e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e+00, tolerance: 1.815e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+00, tolerance: 3.716e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.536e+01, tolerance: 5.537e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.163e+01, tolerance: 5.265e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.390e+01, tolerance: 5.444e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.551e+01, tolerance: 5.568e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.300e+00, tolerance: 9.228e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.897e+00, tolerance: 1.755e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.401e+00, tolerance: 3.716e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+00, tolerance: 3.510e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e-01, tolerance: 1.846e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.146e-01, tolerance: 1.755e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.636e-01, tolerance: 1.815e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.123e+00, tolerance: 9.228e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.882e+00, tolerance: 8.774e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e-01, tolerance: 8.774e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.812e+00, tolerance: 9.280e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.447e+00, tolerance: 9.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+01, tolerance: 3.712e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.171e+01, tolerance: 3.716e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.389e+00, tolerance: 9.228e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.200e+00, tolerance: 8.774e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.148e+00, tolerance: 9.074e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.569e+00, tolerance: 9.280e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.435e+00, tolerance: 9.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.785e+00, tolerance: 9.074e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e+00, tolerance: 9.280e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/roma/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.083e+00, tolerance: 9.290e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=15,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['squared_error',\n",
       "                                                      'absolute_error',\n",
       "                                                      'poisson'],\n",
       "                                        'max_depth': [5, 10, 15, 20, 30, None],\n",
       "                                        'min_samples_leaf': [2, 3, 4],\n",
       "                                        'min_samples_split': [2, 3, 5, 7, 10],\n",
       "                                        'n_estimators': [5, 10, 20, 40, 80, 100,\n",
       "                                                         150, 300, 600, 1000]},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
       "                            'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "389d5b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_depth': 15,\n",
       " 'criterion': 'absolute_error'}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestReg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "edf4ccba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.134471\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'n_estimators': 80, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 15, 'criterion': 'absolute_error'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092414</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>5</td>\n",
       "      <td>88.414701</td>\n",
       "      <td>0.598364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134471</td>\n",
       "      <td>0.035261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd\n",
       "0    MEA     5   0.092414      0.001603\n",
       "0     R2     5  88.414701      0.598364\n",
       "0   RMSE     5   0.134471      0.035261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomForestReg_results = get_results(randomForestReg, 'Random Forest')\n",
    "display(randomForestReg_results.loc[:, 'Scorer' : 'BestScoreStd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f139938",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a3f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbEst = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d445ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\"learning_rate\": [0.01, 0.1, 0.5],\n",
    "               \"n_estimators\": [50, 500, 1000],\n",
    "               \"max_depth\": [3, 5, 30],\n",
    "               \"num_leaves\": [2, 3, 4, 5, 20, 100],\n",
    "               \"reg_lambda\": [0, 3],\n",
    "               \"colsample_bytree\": [0.5, 0.8, 0.99, 1],\n",
    "               \"min_child_weight\": [1e-3, 1, 10, 30]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e84512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lightgbm = LGBMRegressor(objective='regression', \\n                                       num_leaves=4,\\n                                       learning_rate=0.01, \\n                                       n_estimators=5000,\\n                                       max_bin=200, \\n                                       bagging_fraction=0.75,\\n                                       bagging_freq=5, \\n                                       bagging_seed=7,\\n                                       feature_fraction=0.2,\\n                                       feature_fraction_seed=7,\\n                                       verbose=-1,\\n                                       )\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af269fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = RandomizedSearchCV(estimator = lgbEst, param_distributions = param_lgb, n_iter = 30,\n",
    "                           scoring=['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2'],\n",
    "                           n_jobs=-1, refit = 'neg_mean_squared_error',\n",
    "                           cv = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d926337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.8, 0.99, 1],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.5],\n",
       "                                        'max_depth': [3, 5, 30],\n",
       "                                        'min_child_weight': [0.001, 1, 10, 30],\n",
       "                                        'n_estimators': [50, 500, 1000],\n",
       "                                        'num_leaves': [2, 3, 4, 5, 20, 100],\n",
       "                                        'reg_lambda': [0, 3]},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
       "                            'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000ad802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 3,\n",
       " 'num_leaves': 3,\n",
       " 'n_estimators': 500,\n",
       " 'min_child_weight': 0.001,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.1,\n",
       " 'colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cde6082d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.115342\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'reg_lambda': 3, 'num_leaves': 3, 'n_estimators': 500, 'min_child_weight': 0.001, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEA</td>\n",
       "      <td>7</td>\n",
       "      <td>0.078267</td>\n",
       "      <td>0.002436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>7</td>\n",
       "      <td>91.512738</td>\n",
       "      <td>0.375567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>7</td>\n",
       "      <td>0.115342</td>\n",
       "      <td>0.038720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd\n",
       "0    MEA     7   0.078267      0.002436\n",
       "0     R2     7  91.512738      0.375567\n",
       "0   RMSE     7   0.115342      0.038720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb_results = get_results(lgb, 'lgb')\n",
    "display(lgb_results.loc[:, 'Scorer' : 'BestScoreStd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da5169",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3c30caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import RegressorMixin, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f3355fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    (Example)\n",
    "    XGBRegressor in xgboost for sklearn doesnt have ALL parameters accessible, a simple wrapper to expose them\n",
    "    params = {colsample_bytree=0.9,\n",
    "              learning_rate=0.01,\n",
    "              max_depth=5,\n",
    "              min_child_weight=1,\n",
    "              n_estimators=300,\n",
    "              nthread=-1,\n",
    "              objective='binary:logistic',\n",
    "              seed=0,\n",
    "              silent=True,\n",
    "              subsample=0.8}\n",
    "    a = XGBRegressor(params=params)\n",
    "    a.fit(X_train, y_train)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_round=150, eval_metric=None, early_stopping_rounds=None, **params):\n",
    "        self.params = params\n",
    "        self.num_boost_round = num_round\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.eval_metric = eval_metric\n",
    "        self.xgb = None\n",
    "\n",
    "    def fit(self, X, y, x_val=None, y_val=None):\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        if x_val is not None:\n",
    "            dtest = xgb.DMatrix(x_val, label=y_val)\n",
    "            watchlist = [(dtrain, 'train'), (dtest, 'validation')]\n",
    "            self.xgb = xgb.train(params=self.params,\n",
    "                                 dtrain=dtrain,\n",
    "                                 num_boost_round=self.num_boost_round,\n",
    "                                 early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                 evals=watchlist)\n",
    "        else:\n",
    "            self.xgb = xgb.train(params=self.params,\n",
    "                                 dtrain=dtrain,\n",
    "                                 num_boost_round=self.num_boost_round,\n",
    "                                 early_stopping_rounds=self.early_stopping_rounds)\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        preds = self.xgb.predict(dtest)\n",
    "        return preds\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        self.params.update(params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "732b81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbEst = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e8b77de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = [500, 750, 1000, 3500] \n",
    "max_depth = [3, 4]\n",
    "learning_rate = [0.01, 0.03, 0.1, 0.05]\n",
    "reg_lambda = [0.1, 1e-03, 1e-05, 1, 0.0] \n",
    "reg_alpha= [0.5, 1, 0.0]\n",
    "booster = ['gblinear', 'dart', 'gbtree']  \n",
    "objective = ['reg:tweedie', 'reg:squarederror', 'reg:gamma']\n",
    "\n",
    "param_xgb =\\\n",
    "            dict(\n",
    "                num_boost_round = num_round,\n",
    "                booster = booster,\n",
    "                objective = objective,\n",
    "                learning_rate = learning_rate,\n",
    "                reg_lambda = reg_lambda,\n",
    "                reg_alpha = reg_alpha,\n",
    "                max_depth = max_depth\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "43c11b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Не стоит запускать Xgboost c n_jobs=-1 или какой-то другой параллельной обработкой\n",
    "xgbSearch = RandomizedSearchCV(estimator = xgbEst, param_distributions = param_xgb, n_iter = 30,\n",
    "                           scoring=['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2'],\n",
    "                           n_jobs=1, refit = 'neg_mean_squared_error',\n",
    "                           cv = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8ead6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[18:53:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:53:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:53:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:53:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:53:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:54:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:54:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:54:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"max_depth\", \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:54:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"num_boost_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=XGBRegressor(), n_iter=30, n_jobs=1,\n",
       "                   param_distributions={'booster': ['gblinear', 'dart',\n",
       "                                                    'gbtree'],\n",
       "                                        'learning_rate': [0.01, 0.03, 0.1,\n",
       "                                                          0.05],\n",
       "                                        'max_depth': [3, 4],\n",
       "                                        'num_boost_round': [500, 750, 1000,\n",
       "                                                            3500],\n",
       "                                        'objective': ['reg:tweedie',\n",
       "                                                      'reg:squarederror',\n",
       "                                                      'reg:gamma'],\n",
       "                                        'reg_alpha': [0.5, 1, 0.0],\n",
       "                                        'reg_lambda': [0.1, 0.001, 1e-05, 1,\n",
       "                                                       0.0]},\n",
       "                   refit='neg_mean_squared_error',\n",
       "                   scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
       "                            'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbSearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2fcd09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 1,\n",
       " 'reg_alpha': 0.0,\n",
       " 'objective': 'reg:tweedie',\n",
       " 'num_boost_round': 1000,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.1,\n",
       " 'booster': 'dart'}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e4dff1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.116075\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'reg_lambda': 1, 'reg_alpha': 0.0, 'objective': 'reg:tweedie', 'num_boost_round': 1000, 'max_depth': 3, 'learning_rate': 0.1, 'booster': 'dart'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEA</td>\n",
       "      <td>12</td>\n",
       "      <td>0.080333</td>\n",
       "      <td>0.003636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>12</td>\n",
       "      <td>91.385388</td>\n",
       "      <td>0.679612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>12</td>\n",
       "      <td>0.116075</td>\n",
       "      <td>0.038242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd\n",
       "0    MEA    12   0.080333      0.003636\n",
       "0     R2    12  91.385388      0.679612\n",
       "0   RMSE    12   0.116075      0.038242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = get_results(xgbSearch, 'xgb')\n",
    "display(results.loc[:, 'Scorer' : 'BestScoreStd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc627a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df52003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613aabba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253a49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45626a4b",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0910a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LB 0.18378\n",
    "lgb_preds = np.exp(lgb.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49cab3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = lgb_preds\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test['Id']\n",
    "submission[\"SalePrice\"] = ens\n",
    "submission.to_csv(\"submit_ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d2b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
